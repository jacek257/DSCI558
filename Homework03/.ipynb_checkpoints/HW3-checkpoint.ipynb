{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imdb_df = pd.read_csv('imdb.csv', sep=', ', encoding='utf-8', engine='python',\n",
    "                      error_bad_lines=False, warn_bad_lines=False, dtype=str, na_filter=False).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmd_df = pd.read_csv('tmd.csv', sep=',', encoding='utf-8', \n",
    "                      error_bad_lines=False, warn_bad_lines=False, dtype=str, na_filter=False).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('labeled_data.csv', sep=',', encoding='utf-8', comment='#',\n",
    "                      error_bad_lines=False, warn_bad_lines=False, dtype=str, na_filter=False).fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose at least 3 attributes to make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID'].lstrip('0')\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def title(self):\n",
    "        return self.raw_object['name']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def year(self):\n",
    "        return self.raw_object['year']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def directors(self):\n",
    "        return self.raw_object['director'].split('; ')\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def writers(self):\n",
    "        return self.raw_object['writers'].split('; ')\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def actors(self):\n",
    "        return self.raw_object['actors'].split('; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ds = rltk.Dataset(rltk.DataFrameReader(imdb_df), record_class=IMDBRecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMDRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def title(self):\n",
    "        return self.raw_object['title'].strip()\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def year(self):\n",
    "        return self.raw_object['year'].strip()\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def directors(self):\n",
    "        return self.raw_object['director(s)'].split(';')\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def writers(self):\n",
    "        return self.raw_object['writer(s)'].split(';')\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def actors(self):\n",
    "        return self.raw_object['actor(s)'].split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmd_ds = rltk.Dataset(rltk.DataFrameReader(tmd_df), record_class=TMDRecord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design a blocking techinque and save output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = rltk.HashBlockGenerator()\n",
    "block = bg.generate(\n",
    "    bg.block(imdb_ds, property_='year'),\n",
    "    bg.block(tmd_ds, property_='year')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97286562\n"
     ]
    }
   ],
   "source": [
    "total_pairs = len(imdb_df)*len(tmd_df)\n",
    "print(total_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "true_matches_count = 0\n",
    "true_matches = []\n",
    "for i in range(len(label_df)):\n",
    "    if label_df.iloc[i]['class_label'] == '1':\n",
    "        true_matches_count += 1\n",
    "        true_matches.append((label_df.iloc[i]['ltable.ID'], label_df.iloc[i]['rtable.ID']))\n",
    "\n",
    "print(true_matches_count)\n",
    "# print(true_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "3539061\n"
     ]
    }
   ],
   "source": [
    "cmp_pairs = 0\n",
    "pair_count = 0\n",
    "\n",
    "with open('Jimi_Cao_hw03_blocked.csv', 'w') as fp:\n",
    "    blocking_writer = csv.writer(fp)\n",
    "    \n",
    "    all_pairs = rltk.get_record_pairs(imdb_ds, tmd_ds, block=block)\n",
    "    for imdb_rec, tmd_rec in all_pairs:\n",
    "        cmp_pairs += 1\n",
    "    \n",
    "        if imdb_rec.id and tmd_rec.id:\n",
    "            blocking_writer.writerow([imdb_rec.id, tmd_rec.id])\n",
    "            pair = (imdb_rec.id, tmd_rec.id)\n",
    "            if pair in true_matches:\n",
    "                pair_count += 1\n",
    "            \n",
    "print(pair_count)\n",
    "print(cmp_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reduction Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9636223037668861\n"
     ]
    }
   ],
   "source": [
    "red_ratio = 1-(cmp_pairs/total_pairs)\n",
    "print(red_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pairs completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9921875\n"
     ]
    }
   ],
   "source": [
    "pair_complete = pair_count/true_matches_count\n",
    "print(pair_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Define scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(imd_rec, tmd_redc):\n",
    "    title_score = rltk.jaro_winkler_similarity(imdb_rec.title, tmd_rec.title)\n",
    "    \n",
    "    most_sim = []\n",
    "    for imdb_director in imdb_rec.directors:\n",
    "        sim = []\n",
    "        for tmd_director in tmd_rec.directors:\n",
    "            sim.append(rltk.jaro_distance(imdb_director, tmd_director))\n",
    "        most_sim.append(max(sim))\n",
    "    director_score = sum(most_sim)/len(most_sim)\n",
    "    \n",
    "    conf = 0.7 * title_score + 0.3 * director_score\n",
    "    match = 1 if conf > 0.9 else 0\n",
    "    \n",
    "    return match, conf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predict and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5989\n"
     ]
    }
   ],
   "source": [
    "matches = 0\n",
    "with open('Jimi_Cao_hw03_el.csv', 'w') as fp:\n",
    "    predict_writer = csv.writer(fp)\n",
    "    for imdb_rec, tmd_rec in rltk.get_record_pairs(imdb_ds, tmd_ds, block=block):\n",
    "        match, conf = score(imdb_rec, tmd_rec)\n",
    "        predict_writer.writerow([imdb_rec.id, tmd_rec.id, match])\n",
    "        matches += match\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Record linkage on Labeled Data, predict and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = rltk.GroundTruth()\n",
    "\n",
    "for i in range(len(label_df)):\n",
    "    imdb_id = label_df.iloc[i]['ltable.ID']\n",
    "    tmd_id = label_df.iloc[i]['rtable.ID']\n",
    "    \n",
    "    if label_df.iloc[i]['class_label'] == '1':\n",
    "        gt.add_positive(imdb_id, tmd_id)\n",
    "    else:\n",
    "        gt.add_negative(imdb_id, tmd_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "trial = rltk.Trial(gt)\n",
    "count = 0\n",
    "\n",
    "with open('Jimi_Cao_hw03_el_labeled.csv', 'w') as fp:\n",
    "    predict_writer = csv.writer(fp)\n",
    "    for imdb_rec, tmd_rec in rltk.get_record_pairs(imdb_ds, tmd_ds, ground_truth=gt):\n",
    "        count += 1\n",
    "        match, conf = score(imdb_rec, tmd_rec)\n",
    "        predict_writer.writerow([imdb_rec.id, tmd_rec.id, match])\n",
    "        trial.add_result(imdb_rec, tmd_rec, match, conf)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Report precision, recall, and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial statistics based on Ground-Truth from labeled data:\n",
      "precision: 0.973384030418251\n",
      "recall: 1.0\n",
      "f-measure: 0.9865125240847785\n"
     ]
    }
   ],
   "source": [
    "trial.evaluate()\n",
    "print('Trial statistics based on Ground-Truth from labeled data:')\n",
    "print('precision:', trial.precision)\n",
    "print('recall:', trial.recall)\n",
    "print('f-measure:', trial.f_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, XSD, Namespace, RDF, BNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = Namespace('https://schema.org/')\n",
    "MYNS = Namespace('http://inf558.org/myfakenamespace#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg = Graph()\n",
    "\n",
    "my_kg.bind('myns', MYNS)\n",
    "my_kg.bind('schema', SCHEMA)\n",
    "\n",
    "count = 0\n",
    "for record in imdb_ds:\n",
    "    count += 1\n",
    "    \n",
    "    # make uri\n",
    "    movie_uri = URIRef(MYNS[str(count)])\n",
    "    \n",
    "    # start schema\n",
    "    my_kg.add((movie_uri, RDF.type, SCHEMA['Movie']))\n",
    "    \n",
    "    # add name\n",
    "    my_kg.add((movie_uri, SCHEMA['name'], Literal(record.title)))\n",
    "    \n",
    "    # add release year\n",
    "    my_kg.add((movie_uri, MYNS['releaseYear'], Literal(record.year, datatype=XSD.integer)))\n",
    "    \n",
    "    # add directors\n",
    "    directors = record.directors\n",
    "    for director in directors:\n",
    "        bnode = BNode()\n",
    "        my_kg.add((bnode, RDF.type, SCHEMA['Person']))\n",
    "        my_kg.add((bnode, SCHEMA['name'], Literal(director)))\n",
    "        my_kg.add((movie_uri, SCHEMA['director'], bnode))\n",
    "    \n",
    "    # add actors\n",
    "    actors = record.actors\n",
    "    for actor in actors:\n",
    "        bnode = BNode()\n",
    "        my_kg.add((bnode, RDF.type, SCHEMA['Person']))\n",
    "        my_kg.add((bnode, SCHEMA['name'], Literal(actor)))\n",
    "        my_kg.add((movie_uri, SCHEMA['actor'], bnode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv('Jimi_Cao_hw03_el.csv', names=['IMDB_id', 'TMD_id', 'match'])\n",
    "tmd_matches = pairs[pairs['match'] == 1]['TMD_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in tmd_ds:\n",
    "    if int(record.id) not in tmd_matches:\n",
    "        count += 1\n",
    "    \n",
    "        # make uri\n",
    "        movie_uri = URIRef(MYNS[str(count)])\n",
    "    \n",
    "        # start schema\n",
    "        my_kg.add((movie_uri, RDF.type, SCHEMA['Movie']))\n",
    "    \n",
    "        # add name\n",
    "        my_kg.add((movie_uri, SCHEMA['name'], Literal(record.title)))\n",
    "    \n",
    "        # add release year\n",
    "        my_kg.add((movie_uri, MYNS['releaseYear'], Literal(record.year, datatype=XSD.integer)))\n",
    "    \n",
    "        # add directors\n",
    "        directors = record.directors\n",
    "        for director in directors:\n",
    "            bnode = BNode()\n",
    "            my_kg.add((bnode, RDF.type, SCHEMA['Person']))\n",
    "            my_kg.add((bnode, SCHEMA['name'], Literal(director)))\n",
    "            my_kg.add((movie_uri, SCHEMA['director'], bnode))\n",
    "\n",
    "        # add actors\n",
    "        actors = record.actors\n",
    "        for actor in actors:\n",
    "            bnode = BNode()\n",
    "            my_kg.add((bnode, RDF.type, SCHEMA['Person']))\n",
    "            my_kg.add((bnode, SCHEMA['name'], Literal(actor)))\n",
    "            my_kg.add((movie_uri, SCHEMA['actor'], bnode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg.serialize('Jimi_Cao_hw03_triple.ttl', format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
